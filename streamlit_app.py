import streamlit as st
import requests
import json
import os
from io import BytesIO
import base64
import time
import re

# OCR ë° ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import pytesseract
    from pdf2image import convert_from_bytes
    from PIL import Image, ImageEnhance, ImageFilter
    import cv2
    import numpy as np
    OCR_AVAILABLE = True
except ImportError:
    OCR_AVAILABLE = False

# ì¶”ê°€: json for safe JS escaping
import json as pyjson

# ì§„í–‰ë¥  í‘œì‹œë¥¼ ìœ„í•œ í•¨ìˆ˜
def show_progress(progress_text, progress_value):
    """ì§„í–‰ë¥ ì„ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜"""
    progress_bar = st.progress(progress_value)
    status_text = st.empty()
    status_text.text(progress_text)
    return progress_bar, status_text

# í‘œ êµ¬ì¡° ê°ì§€ ë° ë¶„í•  í•¨ìˆ˜ (ê°œì„ : í•„í„° ì™„í™”, ì…€ ë¶„í•  ì¶”ê°€)
def detect_and_extract_tables(image):
    """í‘œ êµ¬ì¡°ë¥¼ ê°ì§€í•˜ê³  ì…€ë³„ë¡œ ë¶„í• í•˜ì—¬ OCR ì²˜ë¦¬ (ì…€ ë¶„í•  ì¶”ê°€)"""
    try:
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        else:
            gray = image.copy()
        
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        
        # ì»¤ë„ í¬ê¸° ì¡°ì • (ì„  ê°ì§€ ë” ì„¸ë°€)
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 1))
        horizontal_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, horizontal_kernel)
        
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 30))
        vertical_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, vertical_kernel)
        
        table_structure = cv2.addWeighted(horizontal_lines, 0.5, vertical_lines, 0.5, 0.0)
        
        contours, _ = cv2.findContours(table_structure, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        table_regions = []
        cell_regions = []  # ìƒˆë¡œ ì¶”ê°€: ì…€ ëª©ë¡
        for contour in contours:
            area = cv2.contourArea(contour)
            if area > 2000:  # í•„í„° ì™„í™”
                x, y, w, h = cv2.boundingRect(contour)
                if w > 80 and h > 40:  # aspect ratio ê°•í™”
                    table_regions.append((x, y, w, h))
                    
                    # ì…€ ë¶„í• : ìˆ˜í‰/ìˆ˜ì§ ì„  êµì°¨ì ìœ¼ë¡œ ì…€ ê³„ì‚° (ê°„ë‹¨ êµ¬í˜„)
                    h_lines_y = np.unique(np.where(horizontal_lines > 0)[0])
                    v_lines_x = np.unique(np.where(vertical_lines > 0)[1])
                    if len(h_lines_y) > 1 and len(v_lines_x) > 1:
                        h_lines_y = sorted(h_lines_y)
                        v_lines_x = sorted(v_lines_x)
                        for row in range(len(h_lines_y) - 1):
                            for col in range(len(v_lines_x) - 1):
                                cell_x = v_lines_x[col]
                                cell_y = h_lines_y[row]
                                cell_w = v_lines_x[col+1] - cell_x
                                cell_h = h_lines_y[row+1] - cell_y
                                if cell_w > 20 and cell_h > 10:
                                    cell_regions.append((x + cell_x, y + cell_y, cell_w, cell_h))
        
        return table_regions, cell_regions, horizontal_lines, vertical_lines  # cell_regions ì¶”ê°€
    
    except Exception as e:
        st.warning(f"í‘œ êµ¬ì¡° ê°ì§€ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return [], [], None, None

# í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€ í•¨ìˆ˜ (ê°œì„ : í•„í„° ì™„í™”)
def detect_text_regions(image):
    """ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì˜ì—­ì„ ê°ì§€í•˜ì—¬ ë¶„í• """
    try:
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        else:
            gray = image.copy()
        
        # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš©
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        
        # ì ì‘í˜• ì´ì§„í™”
        binary = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)
        
        # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì˜ì—­ í™•ì¥
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        dilated = cv2.dilate(binary, kernel, iterations=2)
        
        # ìœ¤ê³½ì„  ì°¾ê¸°
        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        text_regions = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if area > 50:  # ìµœì†Œ í…ìŠ¤íŠ¸ ì˜ì—­ í¬ê¸° ì™„í™”
                x, y, w, h = cv2.boundingRect(contour)
                # í…ìŠ¤íŠ¸ ì˜ì—­ ë¹„ìœ¨ í™•ì¸ (ë„ˆë¬´ ê°€ëŠ˜ê±°ë‚˜ ì‘ì€ ì˜ì—­ ì œì™¸)
                aspect_ratio = w / h if h > 0 else 0
                if 0.1 < aspect_ratio < 20 and w > 20 and h > 10:
                    text_regions.append((x, y, w, h))
        
        return text_regions
        
    except Exception as e:
        st.warning(f"í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return []

# í•œê¸€ íŠ¹í™” ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ (ê°œì„ : í•´ìƒë„ 4ë°°, bilateralFilter ì¶”ê°€, CLAHE ê°•í™”)
def preprocess_for_korean(image):
    """í•œê¸€ ì¸ì‹ì— ìµœì í™”ëœ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ì •í™•ë„ í–¥ìƒ)"""
    try:
        img_array = np.array(image)
        if len(img_array.shape) == 3:
            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        else:
            gray = img_array
        
        # í•´ìƒë„ 4ë°° ì¦ê°€ (í•œê¸€ íš ë” ì„ ëª…)
        height, width = gray.shape
        gray = cv2.resize(gray, (width * 4, height * 4), interpolation=cv2.INTER_CUBIC)
        
        # ë…¸ì´ì¦ˆ ì œê±° ê°•í™” (bilateralFilter: íš ë³´ì¡´í•˜ë©° ë…¸ì´ì¦ˆ ì œê±°)
        gray = cv2.bilateralFilter(gray, d=5, sigmaColor=75, sigmaSpace=75)
        
        # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ì¶”ê°€ ë…¸ì´ì¦ˆ ì œê±°
        gray = cv2.GaussianBlur(gray, (1, 1), 0)
        
        # ì–¸ìƒ¤í”„ ë§ˆìŠ¤í‚¹ìœ¼ë¡œ í•œê¸€ íš ì„ ëª…í™” ê°•í™”
        gaussian = cv2.GaussianBlur(gray, (0, 0), 3.0)
        unsharp_mask = cv2.addWeighted(gray, 1.8, gaussian, -0.8, 0)  # ë” ê°•í•œ ì„ ëª…í™”
        
        # í•œê¸€ íŠ¹í™” ëŒ€ë¹„ í–¥ìƒ ê°•í™”
        clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(unsharp_mask)
        
        # í•œê¸€ íš ë‘ê»˜ ì •ê·œí™”ë¥¼ ìœ„í•œ ëª¨í´ë¡œì§€ ì—°ì‚°
        kernel = np.ones((1, 1), np.uint8)
        enhanced = cv2.morphologyEx(enhanced, cv2.MORPH_CLOSE, kernel)
        
        # ì ì‘í˜• ì´ì§„í™” (í•œê¸€ì˜ ë‹¤ì–‘í•œ í¬ê¸°ì™€ ë‘ê»˜ì— ëŒ€ì‘, blockSize ì¦ê°€)
        binary = cv2.adaptiveThreshold(enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 3)
        
        # í•œê¸€ ìì†Œ ì—°ê²°ì„± í–¥ìƒì„ ìœ„í•œ ì¶”ê°€ ëª¨í´ë¡œì§€ ì—°ì‚°
        korean_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))  # ë” í° ì»¤ë„
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, korean_kernel)
        
        return binary
        
    except Exception as e:
        st.warning(f"í•œê¸€ íŠ¹í™” ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        # ê¸°ë³¸ ì „ì²˜ë¦¬ë¡œ í´ë°±
        img_array = np.array(image)
        if len(img_array.shape) == 3:
            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        else:
            gray = img_array
        return gray

# í‘œ ì „ìš© OCR ì²˜ë¦¬ í•¨ìˆ˜ (ê°œì„ : ì…€ë³„ ì²˜ë¦¬ ì¶”ê°€, confidence í™œìš©, config í™•ì¥)
def process_table_ocr(image, table_regions, cell_regions):
    """í‘œ êµ¬ì¡°ì— ìµœì í™”ëœ OCR ì²˜ë¦¬"""
    extracted_text = ""
    
    if not table_regions:
        return ""
    
    st.info(f"ğŸ“Š ê°ì§€ëœ í‘œ ê°œìˆ˜: {len(table_regions)} | ì…€ ê°œìˆ˜: {len(cell_regions)}")
    
    for i, (x, y, w, h) in enumerate(table_regions):
        try:
            table_text = f"\n=== í‘œ {i+1} ===\n"
            
            # ì…€ë³„ OCR (ì…€ì´ ìˆìœ¼ë©´ ìš°ì„ )
            if cell_regions:
                for j, (cx, cy, cw, ch) in enumerate(cell_regions):
                    cell_roi = image[cy:cy+ch, cx:cx+cw]
                    processed_cell = preprocess_for_korean(Image.fromarray(cell_roi))
                    
                    # ì…€ ì „ìš© OCR ì„¤ì •ë“¤ (PSM 7/8/10 ì¶”ê°€, kor_vert í¬í•¨)
                    cell_configs = [
                        r'--oem 3 --psm 7 -l kor+eng+kor_vert -c preserve_interword_spaces=1',  # ë‹¨ì¼ ë¼ì¸
                        r'--oem 3 --psm 8 -l kor+eng+kor_vert -c preserve_interword_spaces=1',  # ë‹¨ì¼ ë‹¨ì–´
                        r'--oem 3 --psm 10 -l kor+eng+kor_vert -c preserve_interword_spaces=1',  # ë‹¨ì¼ ë¬¸ì (ì‘ì€ ì…€)
                    ]
                    
                    best_cell_text = ""
                    best_confidence = 0
                    
                    for config in cell_configs:
                        try:
                            data = pytesseract.image_to_data(processed_cell, config=config, output_type='dict')
                            text = ' '.join([t for t, c in zip(data['text'], data['conf']) if c > 50])  # conf > 50 í•„í„°
                            if text.strip():
                                mean_conf = sum(data['conf']) / len(data['conf']) if data['conf'] else 0
                                korean_chars = len(re.findall(r'[ê°€-í£]', text))
                                total_chars = len(re.sub(r'\s', '', text))
                                
                                if total_chars > 0:
                                    confidence = mean_conf * (korean_chars / total_chars)  # Tesseract conf í™œìš©
                                    if confidence > best_confidence:
                                        best_confidence = confidence
                                        best_cell_text = text
                        
                        except Exception:
                            continue
                    
                    if best_cell_text.strip():
                        table_text += f"[ì…€ {j+1}] {best_cell_text}\n"
                        st.success(f"âœ… í‘œ {i+1} ì…€ {j+1} ì²˜ë¦¬ ì™„ë£Œ (ì‹ ë¢°ë„: {best_confidence:.1f})")
                    else:
                        st.warning(f"âš ï¸ í‘œ {i+1} ì…€ {j+1} í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            
            # ì…€ì´ ì—†ìœ¼ë©´ ì „ì²´ í‘œ OCR (ê¸°ì¡´ ë¡œì§ ìœ ì§€, config ê°•í™”)
            else:
                table_roi = image[y:y+h, x:x+w]
                processed_table = preprocess_for_korean(Image.fromarray(table_roi))
                
                table_configs = [
                    r'--oem 3 --psm 6 -l kor+eng+kor_vert -c preserve_interword_spaces=1',
                    r'--oem 3 --psm 4 -l kor+eng+kor_vert -c preserve_interword_spaces=1',
                    r'--oem 3 --psm 3 -l kor+eng+kor_vert -c preserve_interword_spaces=1',
                ]
                
                best_table_text = ""
                best_confidence = 0
                
                for config in table_configs:
                    try:
                        data = pytesseract.image_to_data(processed_table, config=config, output_type='dict')
                        text = ' '.join([t for t, c in zip(data['text'], data['conf']) if c > 50])
                        if text.strip():
                            mean_conf = sum(data['conf']) / len(data['conf']) if data['conf'] else 0
                            korean_chars = len(re.findall(r'[ê°€-í£]', text))
                            total_chars = len(re.sub(r'\s', '', text))
                            
                            if total_chars > 0:
                                confidence = mean_conf * (korean_chars / total_chars) * len(text.strip())
                                if confidence > best_confidence:
                                    best_confidence = confidence
                                    best_table_text = text
                    
                    except Exception:
                        continue
                
                if best_table_text.strip():
                    table_text += best_table_text + "\n"
                    st.success(f"âœ… í‘œ {i+1} ì²˜ë¦¬ ì™„ë£Œ (ì‹ ë¢°ë„: {best_confidence:.1f})")
                else:
                    st.warning(f"âš ï¸ í‘œ {i+1} í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            
            extracted_text += table_text
                
        except Exception as e:
            st.warning(f"í‘œ {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            continue
    
    return extracted_text

# í…ìŠ¤íŠ¸ ì˜ì—­ OCR ì²˜ë¦¬ í•¨ìˆ˜ (ê°œì„ : ìƒìœ„ ì œí•œ ì œê±°, ìµœì†Œ conf í•„í„°)
def process_text_regions_ocr(image, text_regions):
    """ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸ ì˜ì—­ì— ìµœì í™”ëœ OCR ì²˜ë¦¬"""
    extracted_text = ""
    
    if not text_regions:
        return ""
    
    st.info(f"ğŸ–¼ï¸ ê°ì§€ëœ í…ìŠ¤íŠ¸ ì˜ì—­ ê°œìˆ˜: {len(text_regions)}")
    
    # í…ìŠ¤íŠ¸ ì˜ì—­ì„ í¬ê¸°ìˆœìœ¼ë¡œ ì •ë ¬ (í° ì˜ì—­ë¶€í„° ì²˜ë¦¬), ì œí•œ ì œê±°
    text_regions = sorted(text_regions, key=lambda x: x[2] * x[3], reverse=True)
    
    for i, (x, y, w, h) in enumerate(text_regions):
        try:
            # í…ìŠ¤íŠ¸ ì˜ì—­ ì¶”ì¶œ (ì—¬ë°± ì¶”ê°€)
            margin = 5
            x_start = max(0, x - margin)
            y_start = max(0, y - margin)
            x_end = min(image.shape[1], x + w + margin)
            y_end = min(image.shape[0], y + h + margin)
            
            text_roi = image[y_start:y_end, x_start:x_end]
            
            # í•œê¸€ íŠ¹í™” ì „ì²˜ë¦¬ ì ìš©
            processed_text = preprocess_for_korean(Image.fromarray(text_roi))
            
            # í…ìŠ¤íŠ¸ ì˜ì—­ ì „ìš© OCR ì„¤ì • (kor_vert ì¶”ê°€)
            text_configs = [
                r'--oem 3 --psm 7 -l kor+eng+kor_vert',  # ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¼ì¸
                r'--oem 3 --psm 8 -l kor+eng+kor_vert',  # ë‹¨ì¼ ë‹¨ì–´
                r'--oem 3 --psm 6 -l kor+eng+kor_vert',  # ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¸”ë¡
                r'--oem 3 --psm 10 -l kor+eng+kor_vert',  # ë‹¨ì¼ ë¬¸ì ì¶”ê°€
            ]
            
            best_text = ""
            best_confidence = 0
            
            for config in text_configs:
                try:
                    data = pytesseract.image_to_data(processed_text, config=config, output_type='dict')
                    text = ' '.join([t for t, c in zip(data['text'], data['conf']) if c > 50])
                    if text.strip():
                        mean_conf = sum(data['conf']) / len(data['conf']) if data['conf'] else 0
                        korean_chars = len(re.findall(r'[ê°€-í£]', text))
                        total_chars = len(re.sub(r'\s', '', text))
                        
                        if total_chars > 0:
                            confidence = mean_conf * (korean_chars / total_chars) * len(text.strip())
                            if confidence > best_confidence:
                                best_confidence = confidence
                                best_text = text
                
                except Exception:
                    continue
            
            if best_text.strip() and best_confidence > 5:  # ìµœì†Œ ì‹ ë¢°ë„ í•„í„°
                extracted_text += f"[í…ìŠ¤íŠ¸ì˜ì—­{i+1}] {best_text.strip()}\n"
                
        except Exception as e:
            continue
    
    return extracted_text

# ê³ ê¸‰ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ (ê°œì„ : í•´ìƒë„ 2ë°° â†’ 4ë°°ë¡œ í†µí•© pre process_for_korean ì‚¬ìš©)
def preprocess_image_advanced(image):
    """ê³ ê¸‰ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ë¡œ OCR ì •í™•ë„ í–¥ìƒ (í‘œ/ì´ë¯¸ì§€ íŠ¹í™”)"""
    return preprocess_for_korean(image)  # í•œê¸€ íŠ¹í™” í•¨ìˆ˜ë¡œ í†µí•©

# í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ í•¨ìˆ˜ (ê°œì„ : ì˜¤ë¥˜ ë”•ì…”ë„ˆë¦¬ í™•ì¥, Markdown í…Œì´ë¸” ì‹œë„)
def postprocess_text(text):
    """OCR ê²°ê³¼ í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ë¡œ ì •í™•ë„ í–¥ìƒ (í‘œ êµ¬ì¡° íŠ¹í™”)"""
    if not text:
        return text
    
    # 1. í‘œ êµ¬ì¡° ì •ë¦¬
    text = re.sub(r'[â”€â”â•]{2,}', 'â”€' * 10, text)  # ê¸´ ìˆ˜í‰ì„ ì„ í‘œì¤€ ê¸¸ì´ë¡œ
    text = re.sub(r'[â”‚â”ƒâ•‘]{2,}', 'â”‚', text)  # ì—°ì†ëœ ìˆ˜ì§ì„ ì„ í•˜ë‚˜ë¡œ
    
    # 2. í‘œ ì…€ êµ¬ë¶„ ê°œì„ 
    text = re.sub(r'\s*[â”‚|]\s*', ' â”‚ ', text)  # í‘œ êµ¬ë¶„ì ì£¼ë³€ ê³µë°± ì •ë¦¬
    text = re.sub(r'\s*[â”€â”Œâ”â””â”˜â”œâ”¤â”¬â”´â”¼]\s*', ' ', text)  # í‘œ ëª¨ì„œë¦¬ ë¬¸ì ì •ë¦¬
    
    # 3. ì¼ë°˜ì ì¸ OCR ì˜¤ë¥˜ ìˆ˜ì • (í™•ì¥)
    corrections = {
        'ã…‡': 'o', 'ã…': 'm', '|': 'l', '0': 'O', '1': 'l',
        'ã„±ã…': 'ã…Œ', 'ã…—ã…': 'ã…', 'ã„´ã…': 'ã…', 'ã„¹ã…': 'ã…', 'ã……ã…': 'ã…‚', 'ã…ˆã…': 'ã…Š', 'ã…‹ã…': 'ã…Œ', 'ã…Œã…': 'ã…', 'ã…ã…': 'ã…',
        'O': '0', 'l': '1', 'S': '5', 'B': '8', 'Z': '2',  # ìˆ«ì/ì˜ë¬¸ í˜¼ë™
        'ì‹ ì •í•˜ì‹ ': 'ì‹ ì²­í•˜ì‹ ', 'ë¯¼í˜„': 'ë¯¼ì›', 'ì§„ë£Œ': 'ì²˜ë¦¬', 'ë‹¤ë¡œê³¼': 'ë‹¤ìŒê³¼', 'ì•Œë¦¬ë“œë¦¬ë‹ˆ': 'ì•Œë ¤ë“œë¦¬ë‹ˆ',  # í…ŒìŠ¤íŠ¸ íŒŒì¼ íŠ¹í™” êµì •
    }
    
    for wrong, correct in corrections.items():
        text = text.replace(wrong, correct)
    
    # 4. ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
    text = re.sub(r'\s+', ' ', text)  # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    text = re.sub(r'\n\s*\n', '\n\n', text)  # ì—°ì†ëœ ì¤„ë°”ê¿ˆ ì •ë¦¬
    
    # 5. í•œê¸€ ë¬¸ì¥ ë¶€í˜¸ ì •ë¦¬
    text = re.sub(r'["""]', '"', text)  # ë”°ì˜´í‘œ í†µì¼
    text = re.sub(r"[''']", "'", text)  # ì‘ì€ë”°ì˜´í‘œ í†µì¼
    text = re.sub(r'[â€¦]', '...', text)  # ë§ì¤„ì„í‘œ í†µì¼
    
    # 6. ìˆ«ìì™€ ë‹¨ìœ„ ì‚¬ì´ ê³µë°± ì •ë¦¬
    text = re.sub(r'(\d)\s+([ê°€-í£]{1,2})', r'\1\2', text)  # "10 ê°œ" -> "10ê°œ"
    text = re.sub(r'(\d)\s+(%|ì›|ë‹¬ëŸ¬|kg|m|cm)', r'\1\2', text)  # "100 %" -> "100%"
    
    # 7. ë‚ ì§œ í˜•ì‹ ì •ë¦¬
    text = re.sub(r'(\d{4})\s*[ë…„]\s*(\d{1,2})\s*[ì›”]\s*(\d{1,2})\s*[ì¼]', r'\1ë…„ \2ì›” \3ì¼', text)
    
    # 8. í‘œ ë‚´ìš© ì •ë¦¬
    text = re.sub(r'(\d+)\s*[.]\s*(\d+)', r'\1.\2', text)  # ì†Œìˆ˜ì  ì •ë¦¬
    text = re.sub(r'(\d+)\s*[,]\s*(\d+)', r'\1,\2', text)  # ì²œë‹¨ìœ„ êµ¬ë¶„ì ì •ë¦¬
    
    # 9. Markdown í…Œì´ë¸” ë³€í™˜ ì‹œë„ (ê°„ë‹¨)
    if 'â”‚' in text or '|' in text:
        text = re.sub(r'(\s*â”‚\s*)', ' | ', text)  # êµ¬ë¶„ì Markdowní™”
        text = re.sub(r'â”€+', '---', text)
    
    return text.strip()

# ë‹¤ë‹¨ê³„ OCR ì²˜ë¦¬ í•¨ìˆ˜ (ê°œì„ : DPI 600, cell_regions í™œìš©)
def extract_text_with_advanced_ocr(pdf_bytes):
    """ê³ ê¸‰ OCRì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ê¸°ë°˜ PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (í‘œ/ì´ë¯¸ì§€ íŠ¹í™”)"""
    if not OCR_AVAILABLE:
        return "OCR ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    try:
        st.info("ğŸ” í‘œ/ì´ë¯¸ì§€ íŠ¹í™” ê³ ê¸‰ OCR ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # PDFë¥¼ ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (DPI ì¦ê°€)
        images = convert_from_bytes(pdf_bytes, dpi=600, fmt='PNG')
        extracted_text = ""
        
        for i, image in enumerate(images):
            st.info(f"ğŸ“„ í˜ì´ì§€ {i+1}/{len(images)} ì²˜ë¦¬ ì¤‘...")
            
            # ì´ë¯¸ì§€ë¥¼ numpy arrayë¡œ ë³€í™˜
            img_array = np.array(image)
            
            # 1. í‘œ êµ¬ì¡° ê°ì§€ ë° ì²˜ë¦¬
            table_regions, cell_regions, h_lines, v_lines = detect_and_extract_tables(img_array)
            table_text = ""
            if table_regions:
                st.info(f"ğŸ“Š í˜ì´ì§€ {i+1}ì—ì„œ {len(table_regions)}ê°œì˜ í‘œ ê°ì§€")
                table_text = process_table_ocr(img_array, table_regions, cell_regions)
            
            # 2. í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€ ë° ì²˜ë¦¬
            text_regions = detect_text_regions(img_array)
            region_text = ""
            if text_regions:
                st.info(f"ğŸ–¼ï¸ í˜ì´ì§€ {i+1}ì—ì„œ {len(text_regions)}ê°œì˜ í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€")
                region_text = process_text_regions_ocr(img_array, text_regions)
            
            # 3. ì „ì²´ í˜ì´ì§€ OCR (ê¸°ë³¸ ì²˜ë¦¬)
            processed_image = preprocess_image_advanced(image)
            
            # ë‹¤ì–‘í•œ OCR ì„¤ì •ë“¤ (kor_vert ì¶”ê°€)
            ocr_configs = [
                {
                    'config': r'--oem 3 --psm 3 -l kor+eng+kor_vert',
                    'name': 'ìë™ í˜ì´ì§€ ë¶„í• '
                },
                {
                    'config': r'--oem 3 --psm 6 -l kor+eng+kor_vert',
                    'name': 'ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¸”ë¡'
                },
                {
                    'config': r'--oem 3 --psm 4 -l kor+eng+kor_vert',
                    'name': 'ë‹¨ì¼ í…ìŠ¤íŠ¸ ì»¬ëŸ¼'
                }
            ]
            
            best_text = ""
            best_confidence = 0
            
            # ì—¬ëŸ¬ OCR ì„¤ì •ìœ¼ë¡œ ì‹œë„
            for config_info in ocr_configs:
                try:
                    data = pytesseract.image_to_data(processed_image, config=config_info['config'], output_type='dict')
                    text = ' '.join([t for t, c in zip(data['text'], data['conf']) if c > 50])
                    
                    if text.strip():
                        mean_conf = sum(data['conf']) / len(data['conf']) if data['conf'] else 0
                        korean_chars = len(re.findall(r'[ê°€-í£]', text))
                        total_chars = len(re.sub(r'\s', '', text))
                        
                        if total_chars > 0:
                            confidence = mean_conf * (korean_chars / total_chars) * len(text.strip())
                            
                            if confidence > best_confidence:
                                best_confidence = confidence
                                best_text = text
                                st.success(f"âœ… ìµœì  ì„¤ì •: {config_info['name']} (ì‹ ë¢°ë„: {confidence:.1f})")
                
                except Exception:
                    continue
            
            # ê²°ê³¼ í†µí•© ë° í›„ì²˜ë¦¬
            page_text = f"\n--- í˜ì´ì§€ {i+1} ---\n"
            
            if table_text.strip():
                page_text += table_text
            
            if region_text.strip():
                page_text += f"\n=== ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸ ===\n{region_text}\n"
            
            if best_text.strip():
                # ê¸°ë³¸ í…ìŠ¤íŠ¸ê°€ ë¶€ì¡±í•œ ê²½ìš° OCR í…ìŠ¤íŠ¸ë¡œ ëŒ€ì²´
                if len(best_text.strip()) > len(table_text + region_text):
                    page_text += f"\n=== ì „ì²´ í˜ì´ì§€ í…ìŠ¤íŠ¸ ===\n{best_text}\n"
                else:
                    # ê¸°ë³¸ í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„í•œ ê²½ìš° ì¶”ê°€ë¡œ ê²°í•©
                    page_text += f"\n=== ì¶”ê°€ í…ìŠ¤íŠ¸ ===\n{best_text}\n"
            
            # í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ ì ìš©
            page_text = postprocess_text(page_text)
            extracted_text += page_text
        
        return extracted_text
        
    except Exception as e:
        return f"OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"

# ë¡œì»¬ PDF ì²˜ë¦¬ í•¨ìˆ˜ (ê°œì„ : íƒ€ì´ë¨¸ ì¶”ê°€ ë¡œì§)
def process_pdf_locally(request_data, progress_callback=None):
    """ë¡œì»¬ì—ì„œ PDF ì²˜ë¦¬"""
    start_time = time.time()  # ì‹œì‘ ì‹œê°„ ê¸°ë¡
    estimated_time = 30  # ê³ ì • ì˜ˆìƒ ì‹œê°„ (ì´ˆ), ì‹¤ì œë¡œëŠ” ë™ì ìœ¼ë¡œ ì¡°ì • ê°€ëŠ¥
    
    def update_progress_with_timer(text, value):
        elapsed = time.time() - start_time
        remaining = max(0, estimated_time - elapsed)
        timer_text = f" | ë‚¨ì€ ì‹œê°„: {int(remaining)}ì´ˆ"
        if progress_callback:
            progress_callback(text + timer_text, value)
    
    try:
        # íŒŒì¼ ì¤€ë¹„
        update_progress_with_timer("íŒŒì¼ ì¤€ë¹„ ì¤‘...", 0.1)
        pdf_bytes = base64.b64decode(request_data['pdf_base64'])
        
        # ê¸°ë³¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        update_progress_with_timer("PDF íŒŒì¼ ë””ì½”ë”© ì¤‘...", 0.2)
        
        import PyPDF2
        pdf_reader = PyPDF2.PdfReader(BytesIO(pdf_bytes))
        num_pages = len(pdf_reader.pages)
        
        update_progress_with_timer(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘... ({num_pages}í˜ì´ì§€)", 0.3)
        
        extracted_text = ""
        for page_num, page in enumerate(pdf_reader.pages):
            try:
                page_text = page.extract_text()
                if page_text.strip():
                    extracted_text += page_text + "\n"
            except Exception as e:
                continue
        
        # OCR ì²˜ë¦¬ (ì„ íƒì )
        if request_data.get('use_ocr', False) and OCR_AVAILABLE:
            update_progress_with_timer("í‘œ/ì´ë¯¸ì§€ íŠ¹í™” OCRì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...", 0.4)
            ocr_text = extract_text_with_advanced_ocr(pdf_bytes)
            if ocr_text and len(ocr_text.strip()) > len(extracted_text.strip()):
                extracted_text = ocr_text
        
        # ìš”ì•½ ìƒì„±
        if request_data.get('generate_summary', False):
            update_progress_with_timer("ë¬¸ì„œ ìš”ì•½ ìƒì„± ì¤‘...", 0.7)
            # ìš”ì•½ ë¡œì§ (ê¸°ì¡´ ìœ ì§€)
        
        # Q&A ìƒì„±
        if request_data.get('generate_qa', False):
            update_progress_with_timer("ì§ˆë¬¸-ë‹µë³€ ìƒì„± ì¤‘...", 0.9)
            # Q&A ë¡œì§ (ê¸°ì¡´ ìœ ì§€)
        
        update_progress_with_timer("ì²˜ë¦¬ ì™„ë£Œ!", 1.0)
        
        return {
            'extracted_text': extracted_text,
            'text_length': len(extracted_text),
            'pages': num_pages
        }
        
    except Exception as e:
        return {'error': f'PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="HangulPDF AI Converter",
    page_icon="ğŸ“„",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ëª¨ë°”ì¼ ë°˜ì‘í˜• CSS
st.markdown("""
<style>
/* ëª¨ë°”ì¼ ë°˜ì‘í˜• ë””ìì¸ */
@media (max-width: 768px) {
    .main .block-container {
        padding-top: 1rem;
        padding-left: 1rem;
        padding-right: 1rem;
    }
    
    .stTabs [data-baseweb="tab-list"] {
        gap: 0.5rem;
    }
    
    .stTabs [data-baseweb="tab"] {
        padding: 0.5rem 0.75rem;
        font-size: 0.9rem;
    }
}

/* ì •ë³´ ì¹´ë“œ ìŠ¤íƒ€ì¼ */
.info-card {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 1.5rem;
    border-radius: 10px;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    margin: 1rem 0;
}

/* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
.stButton > button {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border: none;
    border-radius: 5px;
    padding: 0.5rem 1rem;
    transition: transform 0.2s;
}

.stButton > button:hover {
    transform: translateY(-2px);
}

/* ì§„í–‰ë¥  ë°” ìŠ¤íƒ€ì¼ */
.stProgress > div > div > div {
    background: linear-gradient(90deg, #ff6b6b, #4ecdc4);
}
</style>
""", unsafe_allow_html=True)

# ë©”ì¸ ì œëª©
st.title("ğŸ“„ HangulPDF AI Converter")
st.markdown("**í•œê¸€ PDF ë¬¸ì„œë¥¼ AIê°€ ì‰½ê²Œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ìë™ ë³€í™˜í•˜ëŠ” ë„êµ¬**")

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    # API í‚¤ ì…ë ¥
    api_key = st.text_input("ğŸ”‘ OpenAI API í‚¤", type="password", help="GPT ê¸°ë°˜ ìš”ì•½ ë° Q&A ìƒì„±ì— í•„ìš”í•©ë‹ˆë‹¤.")
    
    st.header("ğŸ”§ ë³€í™˜ ì˜µì…˜")
    
    # ë³€í™˜ ì˜µì…˜ë“¤
    extract_text = st.checkbox("ğŸ“ í…ìŠ¤íŠ¸ ì¶”ì¶œ", value=True, help="PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")
    
    use_ocr = st.checkbox(
        "ğŸ” OCR ì‚¬ìš©", 
        value=False, 
        disabled=not OCR_AVAILABLE,
        help="ì´ë¯¸ì§€ ê¸°ë°˜ PDFë‚˜ ìŠ¤ìº”ëœ ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. ì²˜ë¦¬ ì‹œê°„ì´ ë” ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )
    
    if not OCR_AVAILABLE:
        st.warning("âš ï¸ OCR ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    generate_summary = st.checkbox("ğŸ“‹ ìš”ì•½ ìƒì„±", value=False, help="OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.")
    generate_qa = st.checkbox("â“ ì§ˆë¬¸-ë‹µë³€ ìƒì„±", value=False, help="ë¬¸ì„œ ë‚´ìš© ê¸°ë°˜ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.")
    
    if (generate_summary or generate_qa) and not api_key:
        st.warning("âš ï¸ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

# ë©”ì¸ íƒ­
tab1, tab2, tab3 = st.tabs(["ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ“Š ë³€í™˜ ê²°ê³¼", "ğŸ”— ê³µìœ  & ë‚´ë³´ë‚´ê¸°"])

with tab1:
    st.header("ğŸ“¤ PDF íŒŒì¼ ì—…ë¡œë“œ")
    
    uploaded_file = st.file_uploader(
        "PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        type=['pdf'],
        help="ìµœëŒ€ 200MBê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    )
    
    if uploaded_file is not None:
        # íŒŒì¼ ì •ë³´ í‘œì‹œ
        file_size = len(uploaded_file.getvalue())
        
        st.markdown(f"""
        <div class="info-card">
            <h4>ğŸ“ ì—…ë¡œë“œëœ íŒŒì¼ ì •ë³´</h4>
            <p><strong>ğŸ“ íŒŒì¼ëª…:</strong> {uploaded_file.name}</p>
            <p><strong>ğŸ“ íŒŒì¼ í¬ê¸°:</strong> {file_size:,} bytes</p>
            <p><strong>ğŸ“‹ íŒŒì¼ íƒ€ì…:</strong> {uploaded_file.type}</p>
        </div>
        """, unsafe_allow_html=True)
        
        # OCR ëª¨ë“œ ì•ˆë‚´
        if use_ocr:
            st.info("ğŸ” OCR ëª¨ë“œ: ì´ë¯¸ì§€ ê¸°ë°˜ PDFì—ì„œë„ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. ì²˜ë¦¬ ì‹œê°„ì´ ë” ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.info("ğŸ“„ ê¸°ë³¸ ëª¨ë“œ: í…ìŠ¤íŠ¸ ê¸°ë°˜ PDFì—ì„œë§Œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. ë¹ ë¥¸ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        # ë³€í™˜ ë²„íŠ¼
        if st.button("ğŸš€ ë³€í™˜ ì‹œì‘", type="primary"):
            # ì§„í–‰ë¥  í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            def update_progress(text, value):
                progress_bar.progress(value)
                status_text.text(text)
            
            # PDF ì²˜ë¦¬
            pdf_bytes = uploaded_file.getvalue()
            pdf_base64 = base64.b64encode(pdf_bytes).decode('utf-8')
            
            request_data = {
                'pdf_base64': pdf_base64,
                'extract_text': extract_text,
                'use_ocr': use_ocr,
                'generate_summary': generate_summary,
                'generate_qa': generate_qa,
                'api_key': api_key
            }
            
            # ë¡œì»¬ ì²˜ë¦¬
            result = process_pdf_locally(request_data, update_progress)
            
            # ê²°ê³¼ ì €ì¥
            st.session_state.conversion_result = result
            st.session_state.uploaded_filename = uploaded_file.name
            
            if 'error' not in result:
                st.success("âœ… ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.balloons()
            else:
                st.error(f"âŒ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {result['error']}")

with tab2:
    st.header("ğŸ“Š ë³€í™˜ ê²°ê³¼")
    
    if 'conversion_result' in st.session_state:
        result = st.session_state.conversion_result
        
        if 'error' not in result:
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼
            if 'extracted_text' in result:
                st.subheader("ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸")
                
                # í…ìŠ¤íŠ¸ ì •ë³´
                text_length = result.get('text_length', 0)
                pages = result.get('pages', 0)
                
                st.markdown(f"""
                <div class="info-card">
                    <h4>ğŸ“Š í…ìŠ¤íŠ¸ ì •ë³´</h4>
                    <p><strong>ğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´:</strong> {text_length:,} ê¸€ì</p>
                    <p><strong>ğŸ“„ í˜ì´ì§€ ìˆ˜:</strong> {pages} í˜ì´ì§€</p>
                </div>
                """, unsafe_allow_html=True)
                
                # í…ìŠ¤íŠ¸ í‘œì‹œ
                st.text_area(
                    "ì¶”ì¶œëœ í…ìŠ¤íŠ¸:",
                    value=result['extracted_text'],
                    height=400,
                    key="extracted_text_display"
                )
            
            # ìš”ì•½ ê²°ê³¼
            if 'summary' in result:
                st.subheader("ğŸ“‹ ë¬¸ì„œ ìš”ì•½")
                st.write(result['summary'])
            
            # Q&A ê²°ê³¼
            if 'qa_pairs' in result:
                st.subheader("â“ ì§ˆë¬¸-ë‹µë³€")
                for i, qa in enumerate(result['qa_pairs'], 1):
                    st.write(f"**Q{i}:** {qa['question']}")
                    st.write(f"**A{i}:** {qa['answer']}")
                    st.write("---")
        
        else:
            st.error(f"âŒ {result['error']}")
    
    else:
        st.info("ğŸ“¤ ë¨¼ì € PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë³€í™˜í•´ì£¼ì„¸ìš”.")

with tab3:
    st.header("ğŸ”— ê³µìœ  & ë‚´ë³´ë‚´ê¸°")
    
    if 'conversion_result' in st.session_state:
        result = st.session_state.conversion_result
        
        if 'error' not in result and 'extracted_text' in result:
            extracted_text = result['extracted_text']
            
            # ChatGPT í”„ë¡¬í”„íŠ¸
            st.markdown("**ğŸ’¬ ChatGPT í”„ë¡¬í”„íŠ¸:**")
            chatgpt_prompt = f"""ë‹¤ìŒ í•œê¸€ ë¬¸ì„œë¥¼ AIê°€ ìë™ ë¶„ì„í•œ ë’¤, ë¬¸ì„œ ìœ í˜•ê³¼ ì£¼ìš” ë‚´ìš©ì„ íŒŒì•…í•˜ì—¬ ë‹¤ìŒ í•­ëª©ë“¤ì„ í¬í•¨í•œ ìš”ì•½ ë° êµ¬ì¡°í™”ëœ ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

1. ğŸ“‚ ë¬¸ì„œ ê¸°ë³¸ ì •ë³´:
   - ë¬¸ì„œ ì œëª© ë˜ëŠ” ì¶”ì • ì œëª©
   - ì‘ì„± ë‚ ì§œ ë˜ëŠ” ì¶”ì • ì‹œì 
   - ì‘ì„± ì£¼ì²´ ë˜ëŠ” ê´€ë ¨ ê¸°ê´€/ë‹´ë‹¹ì ì¶”ì •
   - ë¬¸ì„œ ëª©ì (ì •ì±… ë¬¸ì„œ, ë³´ê³ ì„œ, ì œì•ˆì„œ, íšŒì˜ë¡ ë“±)

2. ğŸ“‹ êµ¬ì¡° ë¶„ì„:
   - ëª©ì°¨ ë˜ëŠ” ì„¹ì…˜ êµ¬ì„± ì¶”ì •
   - ê° ì„¹ì…˜ë³„ ìš”ì•½ (3ì¤„ ì´ë‚´)
   - í‘œ, ê·¸ë¦¼, ë„í‘œê°€ í¬í•¨ëœ ê²½ìš° í•´ë‹¹ ë‚´ìš© ìš”ì•½

3. ğŸ§  í•µì‹¬ ë‚´ìš© ìš”ì•½ ë° ì¸ì‚¬ì´íŠ¸:
   - ì „ì²´ ë¬¸ì„œì˜ í•µì‹¬ ì£¼ì œ ë° ì£¼ìš” ì£¼ì¥ ìš”ì•½ (5ì¤„ ì´ë‚´)
   - ìì£¼ ë“±ì¥í•˜ëŠ” í‚¤ì›Œë“œ ë° í•µì‹¬ ê°œë…(ë¹ˆë„ ë¶„ì„ í¬í•¨)
   - ë¬¸ì„œ ë‚´ ë“±ì¥í•˜ëŠ” ì¤‘ìš”í•œ ìˆ˜ì¹˜, ë‚ ì§œ, ê³ ìœ ëª…ì‚¬(ì¸ë¬¼, ê¸°ê´€ ë“±) ì¶”ì¶œ
   - ì¤‘ìš”í•œ ê²°ì •ì‚¬í•­, ìš”ì²­ì‚¬í•­, ì¼ì •, ì•¡ì…˜ ì•„ì´í…œ ìë™ ë¶„ë¦¬

4. ğŸ› ï¸ ë¬¸ì„œ ìœ í˜•ë³„ íŠ¹í™” ë¶„ì„ (ìë™ íŒë‹¨í•˜ì—¬ í¬í•¨):
   - âœ… ê¸°íšì•ˆ/ì œì•ˆì„œ: í•µì‹¬ ì•„ì´ë””ì–´, ì œì•ˆ ë°°ê²½, ê¸°ëŒ€ íš¨ê³¼ ìš”ì•½
   - âœ… íšŒì˜ë¡: ì°¸ì„ì, ì£¼ìš” ë…¼ì˜ì‚¬í•­, ê²°ì •ì‚¬í•­ ë° í›„ì† ì¡°ì¹˜ ì •ë¦¬
   - âœ… ì •ì±…/í–‰ì •ë¬¸ì„œ: ì •ì±… ëª©ì , ëŒ€ìƒ, ì¶”ì§„ ì „ëµ ë° ì¼ì • ìš”ì•½
   - âœ… ê³µì‚¬/ê³„ì•½ë¬¸ì„œ: ê³„ì•½ ì¡°ê±´, ê³µì • ì¼ì •, ì´í•´ê´€ê³„ì ë¶„ì„
   - âœ… ë³´ê³ ì„œ: ë¶„ì„ ëŒ€ìƒ, ë°©ë²•, ê²°ë¡  ë° ì œì–¸ êµ¬ë¶„

5. ğŸ” ì˜¤ë¥˜ ë° ì£¼ì˜ìš”ì†Œ ê°ì§€:
   - ë¬¸ì„œ ë‚´ ë‚ ì§œ ì˜¤ë¥˜, ë…¼ë¦¬ ë¹„ì•½, ëˆ„ë½ ì •ë³´ ìë™ ê°ì§€
   - ë¬¸ë§¥ìƒ í˜¼ë€ì„ ì¤„ ìˆ˜ ìˆëŠ” í‘œí˜„ ë˜ëŠ” ì˜¤íƒˆì ì¶”ì •

6. ğŸ§¾ ê²°ê³¼ ìš”ì•½ í˜•ì‹:
   - ë§ˆí¬ë‹¤ìš´(.md) í˜•ì‹ìœ¼ë¡œ ìš”ì•½ ê²°ê³¼ ì œê³µ
   - ì œëª©, ì†Œì œëª©, ëª©ë¡ ë“±ì„ êµ¬ì¡°ì ìœ¼ë¡œ ì œê³µ

ë¬¸ì„œë¥¼ ì‚¬ëŒì´ ì½ì§€ ì•Šê³ ë„ ì „ì²´ì  íë¦„ê³¼ ì¸ì‚¬ì´íŠ¸ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ë¶„ì„í•´ì£¼ì„¸ìš”.

---

{extracted_text}"""
            
            # ë³µì‚¬ ë²„íŠ¼: JSë¡œ êµ¬í˜„
            js_chatgpt = pyjson.dumps(chatgpt_prompt, ensure_ascii=False)
            st.components.v1.html(
                f"""
                <button onclick="copyChatGPT()" style="margin-left: 10px; padding: 5px 10px; background: #4CAF50; color: white; border: none; border-radius: 3px; cursor: pointer;">ğŸ“‹ ë³µì‚¬í•˜ê¸°</button>
                <script>
                function copyChatGPT() {{
                    navigator.clipboard.writeText({js_chatgpt}).then(function() {{
                        alert('ChatGPT í”„ë¡¬í”„íŠ¸ê°€ ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤!');
                    }});
                }}
                </script>
                """,
                height=40,
            )
            st.text_area(
                "ChatGPTì— ë³µì‚¬í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”:", 
                value=chatgpt_prompt, 
                height=200,
                key="chatgpt_prompt"
            )
            
            # Gemini í”„ë¡¬í”„íŠ¸
            st.markdown("**ğŸ”® Gemini í”„ë¡¬í”„íŠ¸:**")
            gemini_prompt = f"""ë‹¤ìŒ í•œê¸€ ë¬¸ì„œë¥¼ AIê°€ ìë™ ë¶„ì„í•œ ë’¤, ë¬¸ì„œ ìœ í˜•ê³¼ ì£¼ìš” ë‚´ìš©ì„ íŒŒì•…í•˜ì—¬ ë‹¤ìŒ í•­ëª©ë“¤ì„ í¬í•¨í•œ ìš”ì•½ ë° êµ¬ì¡°í™”ëœ ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

1. ğŸ“‚ ë¬¸ì„œ ê¸°ë³¸ ì •ë³´:
   - ë¬¸ì„œ ì œëª© ë˜ëŠ” ì¶”ì • ì œëª©
   - ì‘ì„± ë‚ ì§œ ë˜ëŠ” ì¶”ì • ì‹œì 
   - ì‘ì„± ì£¼ì²´ ë˜ëŠ” ê´€ë ¨ ê¸°ê´€/ë‹´ë‹¹ì ì¶”ì •
   - ë¬¸ì„œ ëª©ì (ì •ì±… ë¬¸ì„œ, ë³´ê³ ì„œ, ì œì•ˆì„œ, íšŒì˜ë¡ ë“±)

2. ğŸ“‹ êµ¬ì¡° ë¶„ì„:
   - ëª©ì°¨ ë˜ëŠ” ì„¹ì…˜ êµ¬ì„± ì¶”ì •
   - ê° ì„¹ì…˜ë³„ ìš”ì•½ (3ì¤„ ì´ë‚´)
   - í‘œ, ê·¸ë¦¼, ë„í‘œê°€ í¬í•¨ëœ ê²½ìš° í•´ë‹¹ ë‚´ìš© ìš”ì•½

3. ğŸ§  í•µì‹¬ ë‚´ìš© ìš”ì•½ ë° ì¸ì‚¬ì´íŠ¸:
   - ì „ì²´ ë¬¸ì„œì˜ í•µì‹¬ ì£¼ì œ ë° ì£¼ìš” ì£¼ì¥ ìš”ì•½ (5ì¤„ ì´ë‚´)
   - ìì£¼ ë“±ì¥í•˜ëŠ” í‚¤ì›Œë“œ ë° í•µì‹¬ ê°œë…(ë¹ˆë„ ë¶„ì„ í¬í•¨)
   - ë¬¸ì„œ ë‚´ ë“±ì¥í•˜ëŠ” ì¤‘ìš”í•œ ìˆ˜ì¹˜, ë‚ ì§œ, ê³ ìœ ëª…ì‚¬(ì¸ë¬¼, ê¸°ê´€ ë“±) ì¶”ì¶œ
   - ì¤‘ìš”í•œ ê²°ì •ì‚¬í•­, ìš”ì²­ì‚¬í•­, ì¼ì •, ì•¡ì…˜ ì•„ì´í…œ ìë™ ë¶„ë¦¬

4. ğŸ› ï¸ ë¬¸ì„œ ìœ í˜•ë³„ íŠ¹í™” ë¶„ì„ (ìë™ íŒë‹¨í•˜ì—¬ í¬í•¨):
   - âœ… ê¸°íšì•ˆ/ì œì•ˆì„œ: í•µì‹¬ ì•„ì´ë””ì–´, ì œì•ˆ ë°°ê²½, ê¸°ëŒ€ íš¨ê³¼ ìš”ì•½
   - âœ… íšŒì˜ë¡: ì°¸ì„ì, ì£¼ìš” ë…¼ì˜ì‚¬í•­, ê²°ì •ì‚¬í•­ ë° í›„ì† ì¡°ì¹˜ ì •ë¦¬
   - âœ… ì •ì±…/í–‰ì •ë¬¸ì„œ: ì •ì±… ëª©ì , ëŒ€ìƒ, ì¶”ì§„ ì „ëµ ë° ì¼ì • ìš”ì•½
   - âœ… ê³µì‚¬/ê³„ì•½ë¬¸ì„œ: ê³„ì•½ ì¡°ê±´, ê³µì • ì¼ì •, ì´í•´ê´€ê³„ì ë¶„ì„
   - âœ… ë³´ê³ ì„œ: ë¶„ì„ ëŒ€ìƒ, ë°©ë²•, ê²°ë¡  ë° ì œì–¸ êµ¬ë¶„

5. ğŸ” ì˜¤ë¥˜ ë° ì£¼ì˜ìš”ì†Œ ê°ì§€:
   - ë¬¸ì„œ ë‚´ ë‚ ì§œ ì˜¤ë¥˜, ë…¼ë¦¬ ë¹„ì•½, ëˆ„ë½ ì •ë³´ ìë™ ê°ì§€
   - ë¬¸ë§¥ìƒ í˜¼ë€ì„ ì¤„ ìˆ˜ ìˆëŠ” í‘œí˜„ ë˜ëŠ” ì˜¤íƒˆì ì¶”ì •

6. ğŸ§¾ ê²°ê³¼ ìš”ì•½ í˜•ì‹:
   - ë§ˆí¬ë‹¤ìš´(.md) í˜•ì‹ìœ¼ë¡œ ìš”ì•½ ê²°ê³¼ ì œê³µ
   - ì œëª©, ì†Œì œëª©, ëª©ë¡ ë“±ì„ êµ¬ì¡°ì ìœ¼ë¡œ ì œê³µ

ë¬¸ì„œë¥¼ ì‚¬ëŒì´ ì½ì§€ ì•Šê³ ë„ ì „ì²´ì  íë¦„ê³¼ ì¸ì‚¬ì´íŠ¸ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ë¶„ì„í•´ì£¼ì„¸ìš”.

---

{extracted_text}"""
            
            js_gemini = pyjson.dumps(gemini_prompt, ensure_ascii=False)
            st.components.v1.html(
                f"""
                <button onclick="copyGemini()" style="margin-left: 10px; padding: 5px 10px; background: #4285F4; color: white; border: none; border-radius: 3px; cursor: pointer;">ğŸ“‹ ë³µì‚¬í•˜ê¸°</button>
                <script>
                function copyGemini() {{
                    navigator.clipboard.writeText({js_gemini}).then(function() {{
                        alert('Gemini í”„ë¡¬í”„íŠ¸ê°€ ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤!');
                    }});
                }}
                </script>
                """,
                height=40,
            )
            st.text_area(
                "Geminiì— ë³µì‚¬í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”:", 
                value=gemini_prompt, 
                height=150,
                key="gemini_prompt"
            )
            
            # Grok í”„ë¡¬í”„íŠ¸
            st.markdown("**ğŸš€ Grok í”„ë¡¬í”„íŠ¸:**")
            grok_prompt = f"""Analyze the uploaded Korean-language PDF file and provide the following structured output in Markdown format in Korean:
- Document type, estimated title, date, and author/institution
- Automatic detection of document structure (sections, tables, etc.)
- Summary of each section (up to 3 lines)
- Extraction of key entities (names, organizations, numbers, dates)
- Top keywords by frequency
- Key insights or action items if applicable
- Special treatment based on document type (proposal, report, minutes, etc.)
- Highlight any inconsistencies, logical errors, or missing sections

---

{extracted_text}"""
            
            js_grok = pyjson.dumps(grok_prompt, ensure_ascii=False)
            st.components.v1.html(
                f"""
                <button onclick="copyGrok()" style="margin-left: 10px; padding: 5px 10px; background: #000000; color: white; border: none; border-radius: 3px; cursor: pointer;">ğŸ“‹ ë³µì‚¬í•˜ê¸°</button>
                <script>
                function copyGrok() {{
                    navigator.clipboard.writeText({js_grok}).then(function() {{
                        alert('Grok í”„ë¡¬í”„íŠ¸ê°€ ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤!');
                    }});
                }}
                </script>
                """,
                height=40,
            )
            st.text_area(
                "Grokì— ë³µì‚¬í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”:", 
                value=grok_prompt, 
                height=150,
                key="grok_prompt"
            )
            
        else:
            st.error("ë³€í™˜ ê²°ê³¼ì— ì˜¤ë¥˜ê°€ ìˆì–´ ë‚´ë³´ë‚´ê¸°ë¥¼ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ğŸ“¤ ë¨¼ì € PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë³€í™˜í•´ì£¼ì„¸ìš”.")

# í‘¸í„°
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; padding: 20px;'>
    <p>ğŸ“„ <strong>HangulPDF AI Converter</strong> - í•œê¸€ PDF ë¬¸ì„œ AI ë³€í™˜ ë„êµ¬</p>
    <p>ğŸ”§ í‘œ/ì´ë¯¸ì§€ íŠ¹í™” OCR | ğŸ“± ëª¨ë°”ì¼ ë°˜ì‘í˜• | ğŸš€ ì‹¤ì‹œê°„ ì§„í–‰ë¥  í‘œì‹œ</p>
    <p>ğŸ’¡ ëª¨ë“  ë””ë°”ì´ìŠ¤ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜</p>
</div>
""", unsafe_allow_html=True)

