import streamlit as st
import requests
import json
import os
from io import BytesIO
import base64

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="HangulPDF AI Converter",
    page_icon="ğŸ“„",
    layout="wide"
)

# ì œëª©
st.title("ğŸ“„ HangulPDF AI Converter")
st.markdown("í•œê¸€ PDF ë¬¸ì„œë¥¼ AIê°€ í™œìš©í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜í•˜ê³  ë¶„ì„í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.")

# API ì„œë²„ URL (ë¡œì»¬ ê°œë°œìš©)
API_BASE_URL = "http://localhost:8000"

# ì‚¬ì´ë“œë°” - API í‚¤ ì„¤ì •
st.sidebar.header("ğŸ”‘ API ì„¤ì •")
openai_api_key = st.sidebar.text_input("OpenAI API Key", type="password", value=st.secrets.get("OPENAI_API_KEY", ""))

if not openai_api_key:
    st.warning("âš ï¸ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

# ë©”ì¸ ì»¨í…ì¸ 
tab1, tab2, tab3 = st.tabs(["ğŸ“„ PDF ì—…ë¡œë“œ & ë³€í™˜", "ğŸ“Š ë¶„ì„ ê²°ê³¼", "ğŸ”— ê³µìœ  & ë‚´ë³´ë‚´ê¸°"])

with tab1:
    st.header("PDF íŒŒì¼ ì—…ë¡œë“œ")
    
    uploaded_file = st.file_uploader(
        "PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        type=['pdf'],
        help="í•œê¸€ë¡œ ì‘ì„±ëœ PDF ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”."
    )
    
    if uploaded_file is not None:
        st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
        
        # íŒŒì¼ ì •ë³´ í‘œì‹œ
        file_details = {
            "íŒŒì¼ëª…": uploaded_file.name,
            "íŒŒì¼ í¬ê¸°": f"{len(uploaded_file.getvalue())} bytes",
            "íŒŒì¼ íƒ€ì…": uploaded_file.type
        }
        st.json(file_details)
        
        # ë³€í™˜ ì˜µì…˜
        st.subheader("ğŸ”§ ë³€í™˜ ì˜µì…˜")
        col1, col2 = st.columns(2)
        
        with col1:
            extract_text = st.checkbox("í…ìŠ¤íŠ¸ ì¶”ì¶œ", value=True)
            generate_summary = st.checkbox("ìš”ì•½ ìƒì„±", value=True)
            
        with col2:
            generate_qa = st.checkbox("ì§ˆë¬¸-ë‹µë³€ ìƒì„±", value=False)
            clean_text = st.checkbox("í…ìŠ¤íŠ¸ ì •ì œ", value=True)
        
        # ë³€í™˜ ì‹¤í–‰
        if st.button("ğŸš€ ë³€í™˜ ì‹œì‘", type="primary"):
            with st.spinner("PDFë¥¼ ë¶„ì„í•˜ê³  ë³€í™˜í•˜ëŠ” ì¤‘..."):
                try:
                    # íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©
                    file_content = base64.b64encode(uploaded_file.getvalue()).decode()
                    
                    # ë³€í™˜ ìš”ì²­ ë°ì´í„°
                    request_data = {
                        "file_content": file_content,
                        "filename": uploaded_file.name,
                        "options": {
                            "extract_text": extract_text,
                            "generate_summary": generate_summary,
                            "generate_qa": generate_qa,
                            "clean_text": clean_text
                        },
                        "openai_api_key": openai_api_key
                    }
                    
                    # ì„¸ì…˜ ìƒíƒœì— ê²°ê³¼ ì €ì¥ (API ì„œë²„ ì—†ì´ ì§ì ‘ ì²˜ë¦¬)
                    st.session_state.conversion_result = process_pdf_locally(request_data)
                    st.success("âœ… ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"âŒ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

with tab2:
    st.header("ğŸ“Š ë¶„ì„ ê²°ê³¼")
    
    if 'conversion_result' in st.session_state:
        result = st.session_state.conversion_result
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼
        if 'extracted_text' in result:
            st.subheader("ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸")
            with st.expander("ì „ì²´ í…ìŠ¤íŠ¸ ë³´ê¸°"):
                st.text_area("", value=result['extracted_text'], height=300)
        
        # ìš”ì•½ ê²°ê³¼
        if 'summary' in result:
            st.subheader("ğŸ“‹ ë¬¸ì„œ ìš”ì•½")
            st.markdown(result['summary'])
        
        # ì§ˆë¬¸-ë‹µë³€ ê²°ê³¼
        if 'qa_pairs' in result:
            st.subheader("â“ ìƒì„±ëœ ì§ˆë¬¸-ë‹µë³€")
            for i, qa in enumerate(result['qa_pairs'], 1):
                with st.expander(f"Q{i}: {qa['question']}"):
                    st.write(f"**ë‹µë³€:** {qa['answer']}")
    else:
        st.info("ğŸ“¤ ë¨¼ì € PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë³€í™˜í•´ì£¼ì„¸ìš”.")

with tab3:
    st.header("ğŸ”— ê³µìœ  & ë‚´ë³´ë‚´ê¸°")
    
    if 'conversion_result' in st.session_state:
        result = st.session_state.conversion_result
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ“¤ í…ìŠ¤íŠ¸ ë‚´ë³´ë‚´ê¸°")
            if 'extracted_text' in result:
                st.download_button(
                    label="ğŸ“„ í…ìŠ¤íŠ¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                    data=result['extracted_text'],
                    file_name=f"{uploaded_file.name}_extracted.txt",
                    mime="text/plain"
                )
            
            if 'summary' in result:
                st.download_button(
                    label="ğŸ“‹ ìš”ì•½ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                    data=result['summary'],
                    file_name=f"{uploaded_file.name}_summary.txt",
                    mime="text/plain"
                )
        
        with col2:
            st.subheader("ğŸ¤– AI ëª¨ë¸ ì—°ë™")
            st.markdown("**ChatGPT í”„ë¡¬í”„íŠ¸:**")
            if 'extracted_text' in result:
                chatgpt_prompt = f"ë‹¤ìŒ ë¬¸ì„œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n{result['extracted_text'][:1000]}..."
                st.text_area("", value=chatgpt_prompt, height=150)
            
            st.markdown("**Gemini/Grok ì—°ë™:**")
            st.info("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ë³µì‚¬í•˜ì—¬ ë‹¤ë¥¸ AI ëª¨ë¸ì— ì§ì ‘ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        st.info("ğŸ“¤ ë¨¼ì € PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë³€í™˜í•´ì£¼ì„¸ìš”.")

# ë¡œì»¬ PDF ì²˜ë¦¬ í•¨ìˆ˜
def process_pdf_locally(request_data):
    """PDFë¥¼ ë¡œì»¬ì—ì„œ ì§ì ‘ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    try:
        import pdfplumber
        import openai
        
        # base64 ë””ì½”ë”©
        file_content = base64.b64decode(request_data['file_content'])
        
        # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
        extracted_text = ""
        with pdfplumber.open(BytesIO(file_content)) as pdf:
            for page in pdf.pages:
                text = page.extract_text()
                if text:
                    extracted_text += text + "\n"
        
        result = {"extracted_text": extracted_text}
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        if request_data.get('openai_api_key'):
            client = openai.OpenAI(api_key=request_data['openai_api_key'])
            
            # ìš”ì•½ ìƒì„±
            if request_data['options'].get('generate_summary'):
                try:
                    response = client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[
                            {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ì–´ ë¬¸ì„œ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ìš” ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”."},
                            {"role": "user", "content": f"ë‹¤ìŒ ë¬¸ì„œë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{extracted_text[:3000]}"}
                        ],
                        max_tokens=500
                    )
                    result['summary'] = response.choices[0].message.content
                except Exception as e:
                    result['summary'] = f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
            
            # ì§ˆë¬¸-ë‹µë³€ ìƒì„±
            if request_data['options'].get('generate_qa'):
                try:
                    response = client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[
                            {"role": "system", "content": "ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ 3ê°œì˜ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”."},
                            {"role": "user", "content": f"ë‹¤ìŒ ë¬¸ì„œì—ì„œ ì¤‘ìš”í•œ ì§ˆë¬¸ 3ê°œì™€ ë‹µë³€ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”:\n\n{extracted_text[:2000]}"}
                        ],
                        max_tokens=800
                    )
                    
                    qa_text = response.choices[0].message.content
                    # ê°„ë‹¨í•œ íŒŒì‹± (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ íŒŒì‹± í•„ìš”)
                    qa_pairs = []
                    lines = qa_text.split('\n')
                    current_q = ""
                    current_a = ""
                    
                    for line in lines:
                        if line.startswith('Q') or line.startswith('ì§ˆë¬¸'):
                            if current_q and current_a:
                                qa_pairs.append({"question": current_q, "answer": current_a})
                            current_q = line
                            current_a = ""
                        elif line.startswith('A') or line.startswith('ë‹µë³€'):
                            current_a = line
                        elif current_a and line.strip():
                            current_a += " " + line.strip()
                    
                    if current_q and current_a:
                        qa_pairs.append({"question": current_q, "answer": current_a})
                    
                    result['qa_pairs'] = qa_pairs[:3]  # ìµœëŒ€ 3ê°œ
                    
                except Exception as e:
                    result['qa_pairs'] = [{"question": "ì§ˆë¬¸ ìƒì„± ì˜¤ë¥˜", "answer": str(e)}]
        
        return result
        
    except Exception as e:
        return {"error": f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"}

# í‘¸í„°
st.markdown("---")
st.markdown("ğŸ”§ **HangulPDF AI Converter** | í•œê¸€ PDF ë¬¸ì„œ AI ë³€í™˜ ë„êµ¬")

